{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../dataset_indice_prix_moyens.xlsx', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séléction des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = list(df.columns[:-1]) #ici nous recuperons tous les variables sauf la variable explicative\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation entre les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codification des variables qualitatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertion_dict = {'MOIS': {'JANVIER': 1, 'FEVRIER' : 2, 'MARS': 3, 'AVRIL' : 4, 'MAI' : 5, 'JUIN' : 6, 'JUILLET' : 7, 'AOUT' : 8, 'SEPTEMBRE' : 9, 'OCTOBRE' : 10, 'NOVEMBRE' : 11, 'DECEMBRE' : 12}}\n",
    "\n",
    "df.replace(to_replace=convertion_dict, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables].corr(method='spearman').style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_new = list(df.columns[2:-1]) #ici nous recuperons toutes les variables qui sont correlées\n",
    "\n",
    "variables_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chargement Matrice X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[variables_new]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chargement de vecteur classe y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.columns[-1]]\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation et gestion de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_model = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer_model.fit(X)\n",
    "\n",
    "X = imputer_model.transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X:\n",
    "    plt.hist(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation de l'ensemble de données en sous-ensembles d'entraînement (training set) et de test (test set)\n",
    "Nous optons de faire une segmentation de l'ensemble de données en ensembles d'apprentissage et de test comprenant chacun repectivement <b>70%</b> et <b>30%</b> des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle\n",
    "\n",
    "a. Regression Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_regression = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_reg = modele_regression.score(X_test, y_test)\n",
    "\n",
    "test_error_regression = np.mean((modele_regression.predict(X_test) - y_test) ** 2)\n",
    "\n",
    "train_error_regression = np.mean((modele_regression.predict(X_train) - y_train) ** 2)\n",
    "\n",
    "print('Coefficients: \\n', modele_regression.coef_) # coefficients\n",
    "\n",
    "print ('intercept', modele_regression.intercept_) # la constante\n",
    "\n",
    "print(\"Residual sum of squares test: %.2f\" % test_error_regression) #Erreur quadratique moyenne\n",
    "\n",
    "print(\"Residual sum of squares train: %.2f\" % train_error_regression) #Erreur quadratique moyenne\n",
    "\n",
    "print(\"La précision du modèle de regression est de\", np.round(precision_reg * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fonction de prédiction de modèle de regression multiple\n",
    "\n",
    "indice = ∑〖βi*Xi〗+ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "model = ''\n",
    "for x in modele_regression.coef_:\n",
    "        model = model + str(x)+' * X'+str(i + 1) + ' + '\n",
    "        i = i + 1\n",
    "    \n",
    "model = 'y_predited(INDICE) = '+ model + str(modele_regression.intercept_)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Forêt aléatoire modele de regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forest_predited = modele_forest.predict(X_test)\n",
    "\n",
    "score = r2_score(y_test, y_forest_predited)\n",
    "\n",
    "test_error_forest = np.mean((y_forest_predited - y_test) ** 2)\n",
    "\n",
    "train_error_forest = np.mean((modele_forest.predict(X_train) - y_train) ** 2)\n",
    "\n",
    "print ('nombre d\\'arbre est', len(modele_forest.estimators_)) # le nombre d'arbre\n",
    "\n",
    "print(\"La précision du modèle de forêt aléatoire est de\", np.round(score * 100, 2), \"%\")\n",
    "\n",
    "print(\"Residual sum of squares test: %.2f\" % test_error_forest) #Erreur quadratique moyenne\n",
    "\n",
    "print(\"Residual sum of squares train: %.2f\" % train_error_forest) #Erreur quadratique moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Arbre de decison modèle de regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_arb = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_arb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_arb = modele_arb.score(X_test, y_test)\n",
    "\n",
    "test_error_arb = np.mean((modele_arb.predict(X_test) - y_test) ** 2)\n",
    "\n",
    "train_error_arb = np.mean((modele_arb.predict(X_train) - y_train) ** 2)\n",
    "\n",
    "print(\"Residual sum of squares test: %.2f\" % test_error_arb) #Erreur quadratique moyenne\n",
    "\n",
    "print(\"Residual sum of squares train: %.2f\" % train_error_arb) #Erreur quadratique moyenne\n",
    "\n",
    "print(\"La précision du modèle est de\", np.round(precision_arb * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des modèles\n",
    "\n",
    "Regression multiple, Forêt aléatoire de regression et Arbre de decision de regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"La précision du modèle :\\n Regression multiple est de \",np.round(precision_reg * 100, 2), \"%\", \n",
    "      \"\\n Forêt aléatoire Regression est de \", np.round(score * 100, 2), \"%\",\n",
    "     \"\\n Arbre de decision Regression est de\", np.round(precision_arb * 100, 2), \"%\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = [train_error_regression, train_error_forest, train_error_arb]\n",
    "\n",
    "test_error = [test_error_regression, test_error_forest, test_error_arb]\n",
    "\n",
    "precision_model = [np.round(precision_reg * 100, 2), np.round(score * 100, 2), np.round(precision_arb * 100, 2)]\n",
    "\n",
    "data = {'Train Error' : train_error, 'Test Error' : test_error, 'Précision modele %' : precision_model}\n",
    "\n",
    "models = ['Regression Multiple', 'Forêt alétaoire Regression', 'Arbre de decison regression']\n",
    "\n",
    "df_compare = pd.DataFrame(data, index = models)\n",
    "\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après analyse, nous avons constacté ce qui suit :\n",
    "    - le modèle de regression multiple prédit à 100% et elle commet moins d'erreurs lors de l'apprentissage et teste\n",
    "    - le modèle de Forêt aléatoire prédit à 94,75%\n",
    "    - le modèle d'Arbre de décision prédit à 96,74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction de nouvelle données\n",
    "\n",
    "chargement de nouvelles données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = [[2012, 'JANVIER', 4.83, 4.18, 4.91, 3.44, 4.93, 6.14, 2.24, 2.06, 2.56, 1.11, 4.60, 2.97],\n",
    "        [2022, 'FEVRIER', 0.45, 0.12, 0.14, 0.58, 0.25, 0.21, 0.33, 1.32, 0.25, 0.09, 0.29, 0.29]]\n",
    "\n",
    "INPUT\n",
    "\n",
    "df_new = pd.DataFrame(data = INPUT, columns=variables)\n",
    "\n",
    "#Normalisation des données\n",
    "new_X = df_new[variables_new]\n",
    "\n",
    "new_X = imputer_model.transform(new_X)\n",
    "\n",
    "new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction avec le modèle de Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predited_reg = modele_regression.predict(new_X)\n",
    "y_predited_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction avec le modèle de forêt aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predited_forest = modele_forest.predict(new_X)\n",
    "y_predited_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction avec le modèle d'abre de decison rgression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predited_arb = modele_arb.predict(new_X)\n",
    "y_predited_arb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict ={'INDICE GENERAL REGRESSION' : y_predited_reg, 'INDICE GENERAL FOREST' : y_predited_forest, 'INDICE GENERAL ARBRE' : y_predited_arb}\n",
    "\n",
    "df_clf = pd.DataFrame(dict, columns =['INDICE GENERAL REGRESSION', 'INDICE GENERAL FOREST', 'INDICE GENERAL ARBRE'])\n",
    "\n",
    "out = pd.merge(df_new, df_clf , right_index=True, left_index=True)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation des indices\n",
    "\n",
    "(IPCy-1 - IPCy+1)/IPCy-1  x 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convertion_dict = {'MOIS': {1 : 'JANVIER', 2 : 'FEVRIER', 3: 'MARS', 4 : 'AVRIL', 5 : 'MAI', 6 : 'JUIN', 7 : 'JUILLET', 8 : 'AOUT', 9 : 'SEPTEMBRE', 10 :'OCTOBRE', 11 : 'NOVEMBRE', 12 : 'DECEMBRE'}}\n",
    "\n",
    "def get_indice_in_df(df, year, month) : #cette méthode nous permet de récupérer l'indice dans le df en fonction de l'année et mois\n",
    "    indice = 0.0 \n",
    "    df.replace(to_replace=convertion_dict, inplace=True)\n",
    "    df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['MOIS'] == (month) and row['ANNEE'] == year :\n",
    "            indice = row['INDICE GENERAL']\n",
    "            break\n",
    "            \n",
    "    return indice\n",
    "    \n",
    "min_v = df['ANNEE'].min() #ici nous recuperons l'année min\n",
    "max_v = df['ANNEE'].max() #ici nous récuperons l'année max\n",
    "\n",
    "for m in ['JANVIER', 'FEVRIER', 'MARS', 'AVRIL', 'MAI', 'JUIN', 'JUILLET', 'AOUT', 'SEPTEMBRE', 'OCTOBRE', 'NOVEMBRE', 'DECEMBRE']:\n",
    "    for y in range(min_v, max_v) :\n",
    "        old = get_indice_in_df(df, y, m)\n",
    "        new = get_indice_in_df(df, y + 1, m)\n",
    "        \n",
    "        old = 0 if old is None else old\n",
    "        new = 0 if new is None else new\n",
    "        \n",
    "        variation = 0 if old is None or new is None else ((old - new)/old) * 0.01     \n",
    "        \n",
    "        print(\"I(\", m, \") = ((\", old, \"(\", y, \") - \", new, \"(\", y + 1, \")) / \", old, \"(\", y, \")) * 0.01 = \", variation, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
